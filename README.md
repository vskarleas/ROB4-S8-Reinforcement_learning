# ROB4-S8: Reinforcement Learning

[English](#english-version) | [Fran√ßais](#french-version)

![Reinforcement Learning](https://raw.githubusercontent.com/vskarleas/ROB4-S8-Reinforcement_learning/main/assets/rl_banner.png)

---

## English Version

### ü§ñ Course Overview

This repository contains materials for the Reinforcement Learning course (ROB4-S8), focusing on the theoretical foundations and practical applications of reinforcement learning algorithms in robotics and autonomous systems.

Reinforcement Learning (RL) is a machine learning paradigm where agents learn to make decisions by taking actions in an environment to maximize cumulative rewards. Unlike supervised learning, RL doesn't require labeled examples but instead learns through trial and error, making it particularly suitable for robotics, game playing, and autonomous systems.

### üìö Prerequisites

To make the most of this course, students should have:
- Solid understanding of Python programming
- Familiarity with basic machine learning concepts
- Knowledge of linear algebra and probability theory
- Experience with NumPy, Pandas, and Matplotlib libraries

### üß© Repository Structure

This repository contains Jupyter notebooks for three practical sessions (TPs) that progressively build understanding of reinforcement learning concepts:

```
.
‚îú‚îÄ‚îÄ TP1/
‚îÇ   ‚îî‚îÄ‚îÄ [Jupyter notebooks for first practical session]
‚îú‚îÄ‚îÄ TP2/
‚îÇ   ‚îî‚îÄ‚îÄ [Jupyter notebooks for second practical session]
‚îú‚îÄ‚îÄ TP3/
‚îÇ   ‚îî‚îÄ‚îÄ [Jupyter notebooks for third practical session]
‚îî‚îÄ‚îÄ README.md
```

### üîç Practical Sessions

#### TP1: Foundations of Reinforcement Learning

The first practical session introduces fundamental concepts of reinforcement learning:
- Markov Decision Processes (MDPs)
- Value functions (state-value function V(s) and action-value function Q(s,a))
- The Bellman equation
- Value iteration and policy iteration algorithms
- Implementation of a simple grid world environment

During this session, students learn to formalize problems as MDPs and solve them using dynamic programming methods.

#### TP2: Temporal Difference Learning

The second practical session explores model-free reinforcement learning methods:
- Monte Carlo methods
- Temporal Difference (TD) learning
- Q-learning
- SARSA (State-Action-Reward-State-Action) algorithm
- Exploration vs. exploitation dilemma
- Œµ-greedy policy

Students implement these algorithms in various environments and analyze their convergence properties and performance.

#### TP3: Advanced Reinforcement Learning Techniques

The third practical session covers more advanced topics:
- Function approximation with neural networks
- Deep Q-Networks (DQN)
- Policy gradient methods
- Actor-Critic algorithms
- Multi-agent reinforcement learning
- Applications in robotics simulations

This session bridges the gap between theoretical understanding and practical applications in complex environments.

### üõ†Ô∏è Setup and Installation

1. Clone this repository:
```bash
git clone https://github.com/vskarleas/ROB4-S8-Reinforcement_learning.git
cd ROB4-S8-Reinforcement_learning
```

2. Create a virtual environment (recommended):
```bash
python -m venv rl_env
source rl_env/bin/activate  # On Windows: rl_env\Scripts\activate
```

3. Install the required packages:
```bash
pip install -r requirements.txt
```

4. Launch Jupyter Notebook:
```bash
jupyter notebook
```

### üìñ Additional Resources

- [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book.html) by Richard S. Sutton and Andrew G. Barto
- [Deep Reinforcement Learning Course](https://huggingface.co/deep-rl-course/unit0/introduction) by Hugging Face
- [OpenAI Spinning Up](https://spinningup.openai.com/)
- [David Silver's RL Course](https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ)

### License Information

**ROB4-S8-Reinforcement_learning** ¬© 2025 by **Vasileios Filippos Skarleas** and **Rami Aridi** is licensed under the [Creative Commons Attribution-NonCommercial 4.0 International](https://creativecommons.org/licenses/by-nc/4.0/).

This work also includes content that is not the property of **Vasileios Filippos Skarleas** and **Rami Aridi** and is subject to copyright and other licenses from their respective owners

---

## French Version

### ü§ñ Aper√ßu du Cours

Ce d√©p√¥t contient les mat√©riaux pour le cours d'Apprentissage par Renforcement (ROB4-S8), se concentrant sur les fondements th√©oriques et les applications pratiques des algorithmes d'apprentissage par renforcement en robotique et syst√®mes autonomes.

L'Apprentissage par Renforcement (RL) est un paradigme d'apprentissage automatique o√π les agents apprennent √† prendre des d√©cisions en effectuant des actions dans un environnement pour maximiser les r√©compenses cumulatives. Contrairement √† l'apprentissage supervis√©, le RL ne n√©cessite pas d'exemples √©tiquet√©s mais apprend par essais et erreurs, ce qui le rend particuli√®rement adapt√© √† la robotique, aux jeux et aux syst√®mes autonomes.

### üìö Pr√©requis

Pour tirer le meilleur parti de ce cours, les √©tudiants devraient avoir:
- Une bonne compr√©hension de la programmation Python
- Une familiarit√© avec les concepts de base de l'apprentissage automatique
- Des connaissances en alg√®bre lin√©aire et th√©orie des probabilit√©s
- Une exp√©rience avec les biblioth√®ques NumPy, Pandas et Matplotlib

### üß© Structure du D√©p√¥t

Ce d√©p√¥t contient des notebooks Jupyter pour trois sessions pratiques (TPs) qui construisent progressivement la compr√©hension des concepts d'apprentissage par renforcement:

```
.
‚îú‚îÄ‚îÄ TP1/
‚îÇ   ‚îî‚îÄ‚îÄ [Notebooks Jupyter pour la premi√®re session pratique]
‚îú‚îÄ‚îÄ TP2/
‚îÇ   ‚îî‚îÄ‚îÄ [Notebooks Jupyter pour la deuxi√®me session pratique]
‚îú‚îÄ‚îÄ TP3/
‚îÇ   ‚îî‚îÄ‚îÄ [Notebooks Jupyter pour la troisi√®me session pratique]
‚îî‚îÄ‚îÄ README.md
```

### üîç Sessions Pratiques

#### TP1: Fondements de l'Apprentissage par Renforcement

La premi√®re session pratique introduit les concepts fondamentaux de l'apprentissage par renforcement:
- Processus de D√©cision Markoviens (MDPs)
- Fonctions de valeur (fonction de valeur d'√©tat V(s) et fonction de valeur action-√©tat Q(s,a))
- L'√©quation de Bellman
- Algorithmes d'it√©ration de la valeur et d'it√©ration de la politique
- Impl√©mentation d'un environnement simple de monde en grille

Pendant cette session, les √©tudiants apprennent √† formaliser les probl√®mes sous forme de MDPs et √† les r√©soudre √† l'aide de m√©thodes de programmation dynamique.

#### TP2: Apprentissage par Diff√©rence Temporelle

La deuxi√®me session pratique explore les m√©thodes d'apprentissage par renforcement sans mod√®le:
- M√©thodes de Monte Carlo
- Apprentissage par Diff√©rence Temporelle (TD)
- Q-learning
- Algorithme SARSA (√âtat-Action-R√©compense-√âtat-Action)
- Dilemme exploration vs. exploitation
- Politique Œµ-greedy

Les √©tudiants impl√©mentent ces algorithmes dans divers environnements et analysent leurs propri√©t√©s de convergence et leurs performances.

#### TP3: Techniques Avanc√©es d'Apprentissage par Renforcement

La troisi√®me session pratique couvre des sujets plus avanc√©s:
- Approximation de fonction avec des r√©seaux de neurones
- R√©seaux Q profonds (DQN)
- M√©thodes de gradient de politique
- Algorithmes Acteur-Critique
- Apprentissage par renforcement multi-agents
- Applications dans des simulations robotiques

Cette session fait le pont entre la compr√©hension th√©orique et les applications pratiques dans des environnements complexes.

### üõ†Ô∏è Configuration et Installation

1. Cloner ce d√©p√¥t:
```bash
git clone https://github.com/vskarleas/ROB4-S8-Reinforcement_learning.git
cd ROB4-S8-Reinforcement_learning
```

2. Cr√©er un environnement virtuel (recommand√©):
```bash
python -m venv rl_env
source rl_env/bin/activate  # Sur Windows: rl_env\Scripts\activate
```

3. Installer les packages requis:
```bash
pip install -r requirements.txt
```

4. Lancer Jupyter Notebook:
```bash
jupyter notebook
```

### üìñ Ressources Suppl√©mentaires

- [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book.html) par Richard S. Sutton et Andrew G. Barto
- [Cours d'Apprentissage par Renforcement Profond](https://huggingface.co/deep-rl-course/unit0/introduction) par Hugging Face
- [OpenAI Spinning Up](https://spinningup.openai.com/)
- [Cours de RL de David Silver](https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ)

### License Information

**ROB4-S8-Reinforcement_learning** ¬© 2025 by **Vasileios Filippos Skarleas** and **Rami Aridi** is licensed under the [Creative Commons Attribution-NonCommercial 4.0 International](https://creativecommons.org/licenses/by-nc/4.0/).

This work also includes content that is not the property of **Vasileios Filippos Skarleas** and **Rami Aridi** and is subject to copyright and other licenses from their respective owners
